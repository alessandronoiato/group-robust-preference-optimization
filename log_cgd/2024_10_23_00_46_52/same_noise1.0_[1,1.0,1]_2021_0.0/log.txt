2024-10-23 00:46:55,117 - /Users/noesis/Code/group-robust-preference-optimization/experiments/run_glb_noisy.py[line:215] - INFO: Logging to log_cgd/2024_10_23_00_46_52/same_noise1.0_[1,1.0,1]_2021_0.0
2024-10-23 00:46:55,119 - /Users/noesis/Code/group-robust-preference-optimization/experiments/run_glb_noisy.py[line:216] - INFO: (IB) Seed: 2021
2024-10-23 00:46:55,120 - /Users/noesis/Code/group-robust-preference-optimization/experiments/run_glb_noisy.py[line:217] - INFO: (IB) Data: 300
2024-10-23 00:46:55,251 - /Users/noesis/Code/group-robust-preference-optimization/experiments/run_glb_noisy.py[line:316] - INFO: MLE reward loss: 0.0002, l2 distance: 2194.4385, acc: 1.00.
2024-10-23 00:46:55,252 - /Users/noesis/Code/group-robust-preference-optimization/experiments/run_glb_noisy.py[line:317] - INFO: True reward parameter: [[2. 2. 2. 2.]
 [2. 2. 2. 2.]
 [2. 2. 2. 2.]]
2024-10-23 00:46:55,253 - /Users/noesis/Code/group-robust-preference-optimization/experiments/run_glb_noisy.py[line:318] - INFO: MLE reward parameter: [620.22118185 720.0685001  648.99839531 539.36401535]
2024-10-23 00:46:55,457 - /Users/noesis/Code/group-robust-preference-optimization/experiments/run_glb_noisy.py[line:334] - INFO: Learned oracle reward: 2.7737, 2.7737, 2.7737
2024-10-23 00:46:56,944 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 0, train_loss: 0.6462, val_loss: 0.6504, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0293, 0.0293, 0.0293, KL_dist: 0.1085, 0.1085, 0.1085, param: [0.6527600288391113, 2.5672714710235596, 3.7133431434631348, 3.5798168182373047], weights: [0.3335435092449188, 0.33309298753738403, 0.33336350321769714], train_wt_loss:  0.6462, val_wt_loss: 0.6504, train_grp_loss: [0.6438608169555664, 0.6534236073493958, 0.6339980959892273], val_grp_loss: [0.6546475291252136, 0.6492623686790466, 0.6470220685005188], max_reward_err: 0.0293, max_reward_err_index: 0, max_kl_dist: 0.1085, max_kl_dist_index: 0, max_train_grp_loss: 0.6534, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6546, max_val_grp_loss_index: 0
2024-10-23 00:46:57,806 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 1, train_loss: 0.6462, val_loss: 0.6503, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0293, 0.0293, 0.0293, KL_dist: 0.1085, 0.1085, 0.1085, param: [0.6533249020576477, 2.567607879638672, 3.7139008045196533, 3.580188751220703], weights: [0.3337537348270416, 0.3328527510166168, 0.33339357376098633], train_wt_loss:  0.6462, val_wt_loss: 0.6503, train_grp_loss: [0.643851101398468, 0.6534160375595093, 0.6339890956878662], val_grp_loss: [0.6546398401260376, 0.6492542028427124, 0.6470130681991577], max_reward_err: 0.0293, max_reward_err_index: 0, max_kl_dist: 0.1085, max_kl_dist_index: 0, max_train_grp_loss: 0.6534, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6546, max_val_grp_loss_index: 0
2024-10-23 00:46:58,628 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 2, train_loss: 0.6462, val_loss: 0.6503, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0293, 0.0293, 0.0293, KL_dist: 0.1086, 0.1086, 0.1086, param: [0.6538897752761841, 2.567944288253784, 3.714458465576172, 3.5805606842041016], weights: [0.33396393060684204, 0.3326125741004944, 0.3334234952926636], train_wt_loss:  0.6461, val_wt_loss: 0.6503, train_grp_loss: [0.6438413858413696, 0.6534082889556885, 0.6339800357818604], val_grp_loss: [0.6546322107315063, 0.649246096611023, 0.6470043063163757], max_reward_err: 0.0293, max_reward_err_index: 0, max_kl_dist: 0.1086, max_kl_dist_index: 0, max_train_grp_loss: 0.6534, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6546, max_val_grp_loss_index: 0
2024-10-23 00:46:59,455 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 3, train_loss: 0.6462, val_loss: 0.6503, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0293, 0.0293, 0.0293, KL_dist: 0.1086, 0.1086, 0.1086, param: [0.6544546484947205, 2.5682806968688965, 3.7150161266326904, 3.5809326171875], weights: [0.33417415618896484, 0.3323725163936615, 0.33345332741737366], train_wt_loss:  0.6461, val_wt_loss: 0.6503, train_grp_loss: [0.6438315510749817, 0.6534007787704468, 0.6339710354804993], val_grp_loss: [0.6546245813369751, 0.6492379903793335, 0.6469953060150146], max_reward_err: 0.0293, max_reward_err_index: 0, max_kl_dist: 0.1086, max_kl_dist_index: 0, max_train_grp_loss: 0.6534, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6546, max_val_grp_loss_index: 0
2024-10-23 00:47:00,303 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 4, train_loss: 0.6462, val_loss: 0.6503, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0293, 0.0293, 0.0293, KL_dist: 0.1086, 0.1086, 0.1086, param: [0.6550195813179016, 2.568617105484009, 3.715574026107788, 3.5813045501708984], weights: [0.33438438177108765, 0.3321325480937958, 0.3334830403327942], train_wt_loss:  0.6461, val_wt_loss: 0.6503, train_grp_loss: [0.6438217163085938, 0.6533930897712708, 0.6339620351791382], val_grp_loss: [0.6546168923377991, 0.6492298245429993, 0.6469865441322327], max_reward_err: 0.0293, max_reward_err_index: 0, max_kl_dist: 0.1086, max_kl_dist_index: 0, max_train_grp_loss: 0.6534, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6546, max_val_grp_loss_index: 0
2024-10-23 00:47:01,138 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 5, train_loss: 0.6462, val_loss: 0.6503, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0293, 0.0293, 0.0293, KL_dist: 0.1086, 0.1086, 0.1086, param: [0.6555845141410828, 2.568953514099121, 3.7161319255828857, 3.581676483154297], weights: [0.3345946669578552, 0.3318926990032196, 0.33351266384124756], train_wt_loss:  0.6461, val_wt_loss: 0.6503, train_grp_loss: [0.6438119411468506, 0.6533854603767395, 0.6339529156684875], val_grp_loss: [0.6546093225479126, 0.6492215991020203, 0.6469775438308716], max_reward_err: 0.0293, max_reward_err_index: 0, max_kl_dist: 0.1086, max_kl_dist_index: 0, max_train_grp_loss: 0.6534, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6546, max_val_grp_loss_index: 0
2024-10-23 00:47:01,970 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 6, train_loss: 0.6461, val_loss: 0.6503, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0293, 0.0293, 0.0293, KL_dist: 0.1086, 0.1086, 0.1086, param: [0.6561494469642639, 2.5692899227142334, 3.7166898250579834, 3.5820484161376953], weights: [0.3348049223423004, 0.3316529095172882, 0.333542138338089], train_wt_loss:  0.6460, val_wt_loss: 0.6503, train_grp_loss: [0.6438021063804626, 0.653377890586853, 0.6339439153671265], val_grp_loss: [0.6546015739440918, 0.6492134928703308, 0.6469687223434448], max_reward_err: 0.0293, max_reward_err_index: 0, max_kl_dist: 0.1086, max_kl_dist_index: 0, max_train_grp_loss: 0.6534, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6546, max_val_grp_loss_index: 0
2024-10-23 00:47:02,805 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 7, train_loss: 0.6461, val_loss: 0.6503, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0288, 0.0288, 0.0288, KL_dist: 0.1086, 0.1086, 0.1086, param: [0.6567144393920898, 2.5696263313293457, 3.717247724533081, 3.582420587539673], weights: [0.335015207529068, 0.331413209438324, 0.33357155323028564], train_wt_loss:  0.6460, val_wt_loss: 0.6503, train_grp_loss: [0.6437923312187195, 0.653370201587677, 0.6339349150657654], val_grp_loss: [0.6545940637588501, 0.6492053866386414, 0.6469597816467285], max_reward_err: 0.0288, max_reward_err_index: 0, max_kl_dist: 0.1086, max_kl_dist_index: 0, max_train_grp_loss: 0.6534, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6546, max_val_grp_loss_index: 0
2024-10-23 00:47:03,648 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 8, train_loss: 0.6461, val_loss: 0.6503, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0288, 0.0288, 0.0288, KL_dist: 0.1086, 0.1086, 0.1086, param: [0.6572794318199158, 2.569962739944458, 3.7178056240081787, 3.5827927589416504], weights: [0.33522552251815796, 0.3311736583709717, 0.33360087871551514], train_wt_loss:  0.6460, val_wt_loss: 0.6502, train_grp_loss: [0.6437826156616211, 0.6533625721931458, 0.6339259147644043], val_grp_loss: [0.6545863151550293, 0.6491972208023071, 0.6469508409500122], max_reward_err: 0.0288, max_reward_err_index: 0, max_kl_dist: 0.1086, max_kl_dist_index: 0, max_train_grp_loss: 0.6534, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6546, max_val_grp_loss_index: 0
2024-10-23 00:47:04,478 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 9, train_loss: 0.6461, val_loss: 0.6503, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0288, 0.0288, 0.0288, KL_dist: 0.1087, 0.1087, 0.1087, param: [0.6578444242477417, 2.5702991485595703, 3.7183635234832764, 3.583164930343628], weights: [0.33543580770492554, 0.33093416690826416, 0.3336300253868103], train_wt_loss:  0.6459, val_wt_loss: 0.6502, train_grp_loss: [0.6437727808952332, 0.6533549427986145, 0.6339169144630432], val_grp_loss: [0.6545787453651428, 0.6491891741752625, 0.6469420194625854], max_reward_err: 0.0288, max_reward_err_index: 0, max_kl_dist: 0.1087, max_kl_dist_index: 0, max_train_grp_loss: 0.6534, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6546, max_val_grp_loss_index: 0
2024-10-23 00:47:05,357 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 10, train_loss: 0.6461, val_loss: 0.6503, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0288, 0.0288, 0.0288, KL_dist: 0.1087, 0.1087, 0.1087, param: [0.6584094762802124, 2.5706355571746826, 3.718921422958374, 3.5835371017456055], weights: [0.3356461226940155, 0.3306947648525238, 0.3336591124534607], train_wt_loss:  0.6459, val_wt_loss: 0.6502, train_grp_loss: [0.6437629461288452, 0.6533473134040833, 0.6339078545570374], val_grp_loss: [0.6545710563659668, 0.6491810083389282, 0.6469330787658691], max_reward_err: 0.0288, max_reward_err_index: 0, max_kl_dist: 0.1087, max_kl_dist_index: 0, max_train_grp_loss: 0.6533, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6546, max_val_grp_loss_index: 0
2024-10-23 00:47:06,188 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 11, train_loss: 0.6461, val_loss: 0.6503, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0288, 0.0288, 0.0288, KL_dist: 0.1087, 0.1087, 0.1087, param: [0.6589745283126831, 2.570971965789795, 3.7194793224334717, 3.583909273147583], weights: [0.33585646748542786, 0.3304554522037506, 0.33368808031082153], train_wt_loss:  0.6459, val_wt_loss: 0.6502, train_grp_loss: [0.6437532305717468, 0.6533396244049072, 0.633898913860321], val_grp_loss: [0.6545634865760803, 0.649172842502594, 0.6469241976737976], max_reward_err: 0.0288, max_reward_err_index: 0, max_kl_dist: 0.1087, max_kl_dist_index: 0, max_train_grp_loss: 0.6533, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6546, max_val_grp_loss_index: 0
2024-10-23 00:47:07,015 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 12, train_loss: 0.6461, val_loss: 0.6503, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0288, 0.0288, 0.0288, KL_dist: 0.1087, 0.1087, 0.1087, param: [0.6595396399497986, 2.5713083744049072, 3.7200372219085693, 3.5842814445495605], weights: [0.3360668122768402, 0.3302162289619446, 0.3337169587612152], train_wt_loss:  0.6459, val_wt_loss: 0.6502, train_grp_loss: [0.6437433362007141, 0.653331995010376, 0.6338898539543152], val_grp_loss: [0.6545558571815491, 0.6491647362709045, 0.6469153761863708], max_reward_err: 0.0288, max_reward_err_index: 0, max_kl_dist: 0.1087, max_kl_dist_index: 0, max_train_grp_loss: 0.6533, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6546, max_val_grp_loss_index: 0
2024-10-23 00:47:07,848 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 13, train_loss: 0.6461, val_loss: 0.6502, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0288, 0.0288, 0.0288, KL_dist: 0.1087, 0.1087, 0.1087, param: [0.6601047515869141, 2.5716447830200195, 3.720595121383667, 3.584653615951538], weights: [0.33627715706825256, 0.3299770951271057, 0.33374571800231934], train_wt_loss:  0.6458, val_wt_loss: 0.6502, train_grp_loss: [0.6437336206436157, 0.6533243656158447, 0.6338807940483093], val_grp_loss: [0.6545481085777283, 0.6491565704345703, 0.6469064950942993], max_reward_err: 0.0288, max_reward_err_index: 0, max_kl_dist: 0.1087, max_kl_dist_index: 0, max_train_grp_loss: 0.6533, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6545, max_val_grp_loss_index: 0
2024-10-23 00:47:08,701 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 14, train_loss: 0.6461, val_loss: 0.6502, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0288, 0.0288, 0.0288, KL_dist: 0.1087, 0.1087, 0.1087, param: [0.6606698632240295, 2.571981191635132, 3.7211530208587646, 3.5850257873535156], weights: [0.3364875614643097, 0.3297381103038788, 0.3337743878364563], train_wt_loss:  0.6458, val_wt_loss: 0.6502, train_grp_loss: [0.6437239050865173, 0.6533167958259583, 0.6338717937469482], val_grp_loss: [0.6545405387878418, 0.6491484642028809, 0.6468976140022278], max_reward_err: 0.0288, max_reward_err_index: 0, max_kl_dist: 0.1087, max_kl_dist_index: 0, max_train_grp_loss: 0.6533, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6545, max_val_grp_loss_index: 0
2024-10-23 00:47:09,528 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 15, train_loss: 0.6461, val_loss: 0.6502, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0288, 0.0288, 0.0288, KL_dist: 0.1087, 0.1087, 0.1087, param: [0.6612350344657898, 2.572317600250244, 3.7217111587524414, 3.585397958755493], weights: [0.33669793605804443, 0.32949918508529663, 0.3338029086589813], train_wt_loss:  0.6458, val_wt_loss: 0.6501, train_grp_loss: [0.6437140107154846, 0.6533091068267822, 0.6338627338409424], val_grp_loss: [0.6545329093933105, 0.6491402983665466, 0.6468886733055115], max_reward_err: 0.0288, max_reward_err_index: 0, max_kl_dist: 0.1087, max_kl_dist_index: 0, max_train_grp_loss: 0.6533, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6545, max_val_grp_loss_index: 0
2024-10-23 00:47:10,378 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 16, train_loss: 0.6461, val_loss: 0.6502, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0288, 0.0288, 0.0288, KL_dist: 0.1088, 0.1088, 0.1088, param: [0.66180020570755, 2.5726540088653564, 3.722269296646118, 3.5857701301574707], weights: [0.33690834045410156, 0.32926034927368164, 0.3338313400745392], train_wt_loss:  0.6458, val_wt_loss: 0.6501, train_grp_loss: [0.6437042355537415, 0.6533014178276062, 0.6338537335395813], val_grp_loss: [0.6545252799987793, 0.6491321921348572, 0.6468797922134399], max_reward_err: 0.0288, max_reward_err_index: 0, max_kl_dist: 0.1088, max_kl_dist_index: 0, max_train_grp_loss: 0.6533, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6545, max_val_grp_loss_index: 0
2024-10-23 00:47:11,226 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 17, train_loss: 0.6461, val_loss: 0.6502, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0288, 0.0288, 0.0288, KL_dist: 0.1088, 0.1088, 0.1088, param: [0.6623653769493103, 2.5729904174804688, 3.722827434539795, 3.5861423015594482], weights: [0.3371187150478363, 0.3290216028690338, 0.3338596224784851], train_wt_loss:  0.6457, val_wt_loss: 0.6501, train_grp_loss: [0.6436945199966431, 0.6532938480377197, 0.6338446736335754], val_grp_loss: [0.6545175909996033, 0.649124026298523, 0.6468709111213684], max_reward_err: 0.0288, max_reward_err_index: 0, max_kl_dist: 0.1088, max_kl_dist_index: 0, max_train_grp_loss: 0.6533, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6545, max_val_grp_loss_index: 0
2024-10-23 00:47:12,054 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 18, train_loss: 0.6460, val_loss: 0.6502, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0288, 0.0288, 0.0288, KL_dist: 0.1088, 0.1088, 0.1088, param: [0.6629306077957153, 2.573326826095581, 3.7233855724334717, 3.586514472961426], weights: [0.3373291790485382, 0.32878297567367554, 0.33388787508010864], train_wt_loss:  0.6457, val_wt_loss: 0.6501, train_grp_loss: [0.6436846256256104, 0.6532861590385437, 0.6338356733322144], val_grp_loss: [0.6545100212097168, 0.6491159200668335, 0.6468619704246521], max_reward_err: 0.0288, max_reward_err_index: 0, max_kl_dist: 0.1088, max_kl_dist_index: 0, max_train_grp_loss: 0.6533, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6545, max_val_grp_loss_index: 0
2024-10-23 00:47:12,881 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 19, train_loss: 0.6460, val_loss: 0.6502, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0288, 0.0288, 0.0288, KL_dist: 0.1088, 0.1088, 0.1088, param: [0.6634958386421204, 2.5736632347106934, 3.7239437103271484, 3.5868866443634033], weights: [0.3375396132469177, 0.32854440808296204, 0.33391597867012024], train_wt_loss:  0.6457, val_wt_loss: 0.6501, train_grp_loss: [0.6436747908592224, 0.6532785892486572, 0.6338266730308533], val_grp_loss: [0.6545023322105408, 0.6491077542304993, 0.6468531489372253], max_reward_err: 0.0288, max_reward_err_index: 0, max_kl_dist: 0.1088, max_kl_dist_index: 0, max_train_grp_loss: 0.6533, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6545, max_val_grp_loss_index: 0
2024-10-23 00:47:13,706 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 20, train_loss: 0.6460, val_loss: 0.6502, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0288, 0.0288, 0.0288, KL_dist: 0.1088, 0.1088, 0.1088, param: [0.6640610694885254, 2.5739998817443848, 3.724501848220825, 3.587258815765381], weights: [0.33775007724761963, 0.3283059597015381, 0.3339439630508423], train_wt_loss:  0.6457, val_wt_loss: 0.6501, train_grp_loss: [0.643665075302124, 0.653270959854126, 0.6338176727294922], val_grp_loss: [0.6544947624206543, 0.6490997076034546, 0.646844208240509], max_reward_err: 0.0288, max_reward_err_index: 0, max_kl_dist: 0.1088, max_kl_dist_index: 0, max_train_grp_loss: 0.6533, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6545, max_val_grp_loss_index: 0
2024-10-23 00:47:14,536 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 21, train_loss: 0.6460, val_loss: 0.6502, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0288, 0.0288, 0.0288, KL_dist: 0.1088, 0.1088, 0.1088, param: [0.6646263599395752, 2.574336528778076, 3.725059986114502, 3.5876309871673584], weights: [0.33796051144599915, 0.3280676007270813, 0.33397185802459717], train_wt_loss:  0.6456, val_wt_loss: 0.6501, train_grp_loss: [0.6436553001403809, 0.6532633304595947, 0.6338086128234863], val_grp_loss: [0.654487133026123, 0.6490915417671204, 0.6468352675437927], max_reward_err: 0.0288, max_reward_err_index: 0, max_kl_dist: 0.1088, max_kl_dist_index: 0, max_train_grp_loss: 0.6533, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6545, max_val_grp_loss_index: 0
2024-10-23 00:47:15,384 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 22, train_loss: 0.6460, val_loss: 0.6502, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0288, 0.0288, 0.0288, KL_dist: 0.1088, 0.1088, 0.1088, param: [0.665191650390625, 2.5746731758117676, 3.7256181240081787, 3.588003158569336], weights: [0.33817097544670105, 0.3278293311595917, 0.3339996337890625], train_wt_loss:  0.6456, val_wt_loss: 0.6500, train_grp_loss: [0.6436455249786377, 0.6532557010650635, 0.6337996125221252], val_grp_loss: [0.654479444026947, 0.6490833163261414, 0.646826446056366], max_reward_err: 0.0288, max_reward_err_index: 0, max_kl_dist: 0.1088, max_kl_dist_index: 0, max_train_grp_loss: 0.6533, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6545, max_val_grp_loss_index: 0
2024-10-23 00:47:16,219 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 23, train_loss: 0.6460, val_loss: 0.6502, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0288, 0.0288, 0.0288, KL_dist: 0.1089, 0.1089, 0.1089, param: [0.6657570004463196, 2.575009822845459, 3.7261762619018555, 3.5883753299713135], weights: [0.33838149905204773, 0.327591210603714, 0.33402734994888306], train_wt_loss:  0.6456, val_wt_loss: 0.6500, train_grp_loss: [0.6436357498168945, 0.6532480120658875, 0.6337904930114746], val_grp_loss: [0.6544718742370605, 0.6490752100944519, 0.6468175053596497], max_reward_err: 0.0288, max_reward_err_index: 0, max_kl_dist: 0.1089, max_kl_dist_index: 0, max_train_grp_loss: 0.6532, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6545, max_val_grp_loss_index: 0
2024-10-23 00:47:17,044 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 24, train_loss: 0.6460, val_loss: 0.6502, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0288, 0.0288, 0.0288, KL_dist: 0.1089, 0.1089, 0.1089, param: [0.6663223505020142, 2.5753464698791504, 3.7267343997955322, 3.588747501373291], weights: [0.33859196305274963, 0.3273530900478363, 0.3340548872947693], train_wt_loss:  0.6456, val_wt_loss: 0.6500, train_grp_loss: [0.6436259746551514, 0.6532403826713562, 0.6337814927101135], val_grp_loss: [0.6544641852378845, 0.6490671038627625, 0.6468086838722229], max_reward_err: 0.0288, max_reward_err_index: 0, max_kl_dist: 0.1089, max_kl_dist_index: 0, max_train_grp_loss: 0.6532, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6545, max_val_grp_loss_index: 0
2024-10-23 00:47:17,881 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 25, train_loss: 0.6460, val_loss: 0.6502, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0288, 0.0288, 0.0288, KL_dist: 0.1089, 0.1089, 0.1089, param: [0.6668877005577087, 2.575683116912842, 3.727292537689209, 3.5891199111938477], weights: [0.3388024866580963, 0.32711511850357056, 0.33408236503601074], train_wt_loss:  0.6455, val_wt_loss: 0.6500, train_grp_loss: [0.6436160802841187, 0.653232753276825, 0.6337724924087524], val_grp_loss: [0.6544564962387085, 0.649058997631073, 0.6467997431755066], max_reward_err: 0.0288, max_reward_err_index: 0, max_kl_dist: 0.1089, max_kl_dist_index: 0, max_train_grp_loss: 0.6532, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6545, max_val_grp_loss_index: 0
2024-10-23 00:47:18,707 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 26, train_loss: 0.6460, val_loss: 0.6501, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0288, 0.0288, 0.0288, KL_dist: 0.1089, 0.1089, 0.1089, param: [0.6674531102180481, 2.576019763946533, 3.7278506755828857, 3.5894923210144043], weights: [0.339013010263443, 0.326877236366272, 0.33410972356796265], train_wt_loss:  0.6455, val_wt_loss: 0.6500, train_grp_loss: [0.6436063647270203, 0.6532251238822937, 0.6337634921073914], val_grp_loss: [0.654448926448822, 0.649050772190094, 0.6467908024787903], max_reward_err: 0.0288, max_reward_err_index: 0, max_kl_dist: 0.1089, max_kl_dist_index: 0, max_train_grp_loss: 0.6532, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6544, max_val_grp_loss_index: 0
2024-10-23 00:47:19,549 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 27, train_loss: 0.6460, val_loss: 0.6501, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0288, 0.0288, 0.0288, KL_dist: 0.1089, 0.1089, 0.1089, param: [0.6680185198783875, 2.5763564109802246, 3.7284090518951416, 3.589864730834961], weights: [0.33922356367111206, 0.32663947343826294, 0.3341369926929474], train_wt_loss:  0.6455, val_wt_loss: 0.6500, train_grp_loss: [0.6435964703559875, 0.6532174944877625, 0.6337544322013855], val_grp_loss: [0.654441237449646, 0.6490426063537598, 0.6467819213867188], max_reward_err: 0.0288, max_reward_err_index: 0, max_kl_dist: 0.1089, max_kl_dist_index: 0, max_train_grp_loss: 0.6532, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6544, max_val_grp_loss_index: 0
2024-10-23 00:47:20,374 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 28, train_loss: 0.6460, val_loss: 0.6501, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0288, 0.0288, 0.0288, KL_dist: 0.1089, 0.1089, 0.1089, param: [0.6685839295387268, 2.576693058013916, 3.7289674282073975, 3.5902371406555176], weights: [0.33943408727645874, 0.3264017701148987, 0.3341641426086426], train_wt_loss:  0.6455, val_wt_loss: 0.6500, train_grp_loss: [0.6435866951942444, 0.6532098054885864, 0.6337454915046692], val_grp_loss: [0.6544336080551147, 0.6490345597267151, 0.646773099899292], max_reward_err: 0.0288, max_reward_err_index: 0, max_kl_dist: 0.1089, max_kl_dist_index: 0, max_train_grp_loss: 0.6532, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6544, max_val_grp_loss_index: 0
2024-10-23 00:47:21,201 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 29, train_loss: 0.6459, val_loss: 0.6501, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0288, 0.0288, 0.0288, KL_dist: 0.1089, 0.1089, 0.1089, param: [0.6691493988037109, 2.5770297050476074, 3.7295258045196533, 3.590609550476074], weights: [0.3396446406841278, 0.3261641561985016, 0.3341911733150482], train_wt_loss:  0.6454, val_wt_loss: 0.6499, train_grp_loss: [0.643576979637146, 0.6532021760940552, 0.6337363719940186], val_grp_loss: [0.6544260382652283, 0.6490263938903809, 0.6467642188072205], max_reward_err: 0.0288, max_reward_err_index: 0, max_kl_dist: 0.1089, max_kl_dist_index: 0, max_train_grp_loss: 0.6532, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6544, max_val_grp_loss_index: 0
2024-10-23 00:47:22,030 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 30, train_loss: 0.6459, val_loss: 0.6501, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0288, 0.0288, 0.0288, KL_dist: 0.1090, 0.1090, 0.1090, param: [0.6697148680686951, 2.577366352081299, 3.730084180831909, 3.590981960296631], weights: [0.33985522389411926, 0.32592666149139404, 0.3342180848121643], train_wt_loss:  0.6454, val_wt_loss: 0.6499, train_grp_loss: [0.6435671448707581, 0.6531946063041687, 0.6337273120880127], val_grp_loss: [0.6544183492660522, 0.6490182280540466, 0.6467552781105042], max_reward_err: 0.0288, max_reward_err_index: 0, max_kl_dist: 0.1090, max_kl_dist_index: 0, max_train_grp_loss: 0.6532, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6544, max_val_grp_loss_index: 0
2024-10-23 00:47:22,863 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 31, train_loss: 0.6459, val_loss: 0.6501, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0288, 0.0288, 0.0288, KL_dist: 0.1090, 0.1090, 0.1090, param: [0.6702803373336792, 2.5777029991149902, 3.730642557144165, 3.5913543701171875], weights: [0.3400658369064331, 0.32568928599357605, 0.3342449367046356], train_wt_loss:  0.6454, val_wt_loss: 0.6499, train_grp_loss: [0.6435573697090149, 0.6531869173049927, 0.6337183117866516], val_grp_loss: [0.654410719871521, 0.6490100622177124, 0.6467463970184326], max_reward_err: 0.0288, max_reward_err_index: 0, max_kl_dist: 0.1090, max_kl_dist_index: 0, max_train_grp_loss: 0.6532, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6544, max_val_grp_loss_index: 0
2024-10-23 00:47:23,691 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 32, train_loss: 0.6459, val_loss: 0.6501, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0288, 0.0288, 0.0288, KL_dist: 0.1090, 0.1090, 0.1090, param: [0.6708458662033081, 2.5780396461486816, 3.731200933456421, 3.591726779937744], weights: [0.3402763903141022, 0.32545197010040283, 0.334271639585495], train_wt_loss:  0.6454, val_wt_loss: 0.6499, train_grp_loss: [0.643547534942627, 0.6531792879104614, 0.6337093114852905], val_grp_loss: [0.6544030904769897, 0.6490020155906677, 0.6467374563217163], max_reward_err: 0.0288, max_reward_err_index: 0, max_kl_dist: 0.1090, max_kl_dist_index: 0, max_train_grp_loss: 0.6532, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6544, max_val_grp_loss_index: 0
2024-10-23 00:47:24,522 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 33, train_loss: 0.6459, val_loss: 0.6501, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0288, 0.0288, 0.0288, KL_dist: 0.1090, 0.1090, 0.1090, param: [0.671411395072937, 2.578376293182373, 3.7317593097686768, 3.592099189758301], weights: [0.34048697352409363, 0.32521480321884155, 0.3342982530593872], train_wt_loss:  0.6453, val_wt_loss: 0.6499, train_grp_loss: [0.6435378193855286, 0.6531716585159302, 0.6337002515792847], val_grp_loss: [0.6543954014778137, 0.6489938497543335, 0.6467286348342896], max_reward_err: 0.0288, max_reward_err_index: 0, max_kl_dist: 0.1090, max_kl_dist_index: 0, max_train_grp_loss: 0.6532, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6544, max_val_grp_loss_index: 0
2024-10-23 00:47:25,383 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 34, train_loss: 0.6459, val_loss: 0.6501, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0288, 0.0288, 0.0288, KL_dist: 0.1090, 0.1090, 0.1090, param: [0.6719769835472107, 2.5787129402160645, 3.7323176860809326, 3.5924715995788574], weights: [0.3406975567340851, 0.32497769594192505, 0.33432474732398987], train_wt_loss:  0.6453, val_wt_loss: 0.6499, train_grp_loss: [0.6435279250144958, 0.6531640291213989, 0.6336912512779236], val_grp_loss: [0.6543877720832825, 0.648985743522644, 0.6467196345329285], max_reward_err: 0.0288, max_reward_err_index: 0, max_kl_dist: 0.1090, max_kl_dist_index: 0, max_train_grp_loss: 0.6532, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6544, max_val_grp_loss_index: 0
2024-10-23 00:47:26,206 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 35, train_loss: 0.6459, val_loss: 0.6501, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0288, 0.0288, 0.0288, KL_dist: 0.1090, 0.1090, 0.1090, param: [0.6725425720214844, 2.579049587249756, 3.7328760623931885, 3.592844009399414], weights: [0.34090813994407654, 0.3247406780719757, 0.3343510925769806], train_wt_loss:  0.6453, val_wt_loss: 0.6499, train_grp_loss: [0.6435182094573975, 0.6531563997268677, 0.6336822509765625], val_grp_loss: [0.6543801426887512, 0.6489775776863098, 0.6467108726501465], max_reward_err: 0.0288, max_reward_err_index: 0, max_kl_dist: 0.1090, max_kl_dist_index: 0, max_train_grp_loss: 0.6532, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6544, max_val_grp_loss_index: 0
2024-10-23 00:47:27,027 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 36, train_loss: 0.6459, val_loss: 0.6501, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0288, 0.0288, 0.0288, KL_dist: 0.1090, 0.1090, 0.1090, param: [0.6731081604957581, 2.5793862342834473, 3.7334344387054443, 3.5932164192199707], weights: [0.34111878275871277, 0.3245037794113159, 0.33437737822532654], train_wt_loss:  0.6453, val_wt_loss: 0.6498, train_grp_loss: [0.6435083746910095, 0.6531487107276917, 0.6336731314659119], val_grp_loss: [0.65437251329422, 0.6489694714546204, 0.6467019319534302], max_reward_err: 0.0288, max_reward_err_index: 0, max_kl_dist: 0.1090, max_kl_dist_index: 0, max_train_grp_loss: 0.6531, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6544, max_val_grp_loss_index: 0
2024-10-23 00:47:27,853 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 37, train_loss: 0.6459, val_loss: 0.6501, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0288, 0.0288, 0.0288, KL_dist: 0.1091, 0.1091, 0.1091, param: [0.6736738085746765, 2.5797228813171387, 3.7339928150177, 3.5935888290405273], weights: [0.341329425573349, 0.3242669701576233, 0.3344035744667053], train_wt_loss:  0.6452, val_wt_loss: 0.6498, train_grp_loss: [0.6434985995292664, 0.6531410813331604, 0.6336641907691956], val_grp_loss: [0.654364824295044, 0.6489612460136414, 0.6466929316520691], max_reward_err: 0.0288, max_reward_err_index: 0, max_kl_dist: 0.1091, max_kl_dist_index: 0, max_train_grp_loss: 0.6531, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6544, max_val_grp_loss_index: 0
2024-10-23 00:47:28,684 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 38, train_loss: 0.6459, val_loss: 0.6500, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0288, 0.0288, 0.0288, KL_dist: 0.1091, 0.1091, 0.1091, param: [0.674239456653595, 2.58005952835083, 3.734551429748535, 3.593961238861084], weights: [0.3415400981903076, 0.3240302503108978, 0.33442965149879456], train_wt_loss:  0.6452, val_wt_loss: 0.6498, train_grp_loss: [0.6434887647628784, 0.6531335115432739, 0.6336551904678345], val_grp_loss: [0.6543572545051575, 0.6489531397819519, 0.6466841101646423], max_reward_err: 0.0288, max_reward_err_index: 0, max_kl_dist: 0.1091, max_kl_dist_index: 0, max_train_grp_loss: 0.6531, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6544, max_val_grp_loss_index: 0
2024-10-23 00:47:29,518 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 39, train_loss: 0.6459, val_loss: 0.6500, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0288, 0.0288, 0.0288, KL_dist: 0.1091, 0.1091, 0.1091, param: [0.6748051047325134, 2.5803961753845215, 3.73511004447937, 3.5943336486816406], weights: [0.34175077080726624, 0.3237936198711395, 0.3344556391239166], train_wt_loss:  0.6452, val_wt_loss: 0.6498, train_grp_loss: [0.6434789896011353, 0.6531257033348083, 0.6336461901664734], val_grp_loss: [0.6543496251106262, 0.6489449143409729, 0.6466752290725708], max_reward_err: 0.0288, max_reward_err_index: 0, max_kl_dist: 0.1091, max_kl_dist_index: 0, max_train_grp_loss: 0.6531, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6543, max_val_grp_loss_index: 0
2024-10-23 00:47:30,342 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 40, train_loss: 0.6459, val_loss: 0.6500, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0288, 0.0288, 0.0288, KL_dist: 0.1091, 0.1091, 0.1091, param: [0.6753708124160767, 2.580732822418213, 3.735668659210205, 3.5947060585021973], weights: [0.34196141362190247, 0.3235570788383484, 0.33448147773742676], train_wt_loss:  0.6452, val_wt_loss: 0.6498, train_grp_loss: [0.6434691548347473, 0.6531182527542114, 0.6336371898651123], val_grp_loss: [0.654341995716095, 0.6489368081092834, 0.6466663479804993], max_reward_err: 0.0288, max_reward_err_index: 0, max_kl_dist: 0.1091, max_kl_dist_index: 0, max_train_grp_loss: 0.6531, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6543, max_val_grp_loss_index: 0
2024-10-23 00:47:31,163 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 41, train_loss: 0.6458, val_loss: 0.6500, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0288, 0.0288, 0.0288, KL_dist: 0.1091, 0.1091, 0.1091, param: [0.6759365200996399, 2.5810694694519043, 3.73622727394104, 3.595078468322754], weights: [0.3421720862388611, 0.3233206570148468, 0.3345072269439697], train_wt_loss:  0.6451, val_wt_loss: 0.6498, train_grp_loss: [0.6434594392776489, 0.6531105637550354, 0.6336281299591064], val_grp_loss: [0.6543343663215637, 0.648928701877594, 0.646657407283783], max_reward_err: 0.0288, max_reward_err_index: 0, max_kl_dist: 0.1091, max_kl_dist_index: 0, max_train_grp_loss: 0.6531, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6543, max_val_grp_loss_index: 0
2024-10-23 00:47:31,984 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 42, train_loss: 0.6458, val_loss: 0.6500, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0288, 0.0288, 0.0288, KL_dist: 0.1091, 0.1091, 0.1091, param: [0.6765022873878479, 2.5814061164855957, 3.736785888671875, 3.5954508781433105], weights: [0.3423827886581421, 0.3230843245983124, 0.33453285694122314], train_wt_loss:  0.6451, val_wt_loss: 0.6498, train_grp_loss: [0.643449604511261, 0.6531028151512146, 0.6336190700531006], val_grp_loss: [0.6543267369270325, 0.6489205360412598, 0.6466485261917114], max_reward_err: 0.0288, max_reward_err_index: 0, max_kl_dist: 0.1091, max_kl_dist_index: 0, max_train_grp_loss: 0.6531, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6543, max_val_grp_loss_index: 0
2024-10-23 00:47:32,824 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 43, train_loss: 0.6458, val_loss: 0.6500, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0288, 0.0288, 0.0288, KL_dist: 0.1091, 0.1091, 0.1091, param: [0.6770680546760559, 2.581742763519287, 3.73734450340271, 3.5958235263824463], weights: [0.3425934910774231, 0.3228480815887451, 0.3345583975315094], train_wt_loss:  0.6451, val_wt_loss: 0.6497, train_grp_loss: [0.6434398293495178, 0.6530951857566833, 0.6336100101470947], val_grp_loss: [0.6543190479278564, 0.6489124298095703, 0.6466396450996399], max_reward_err: 0.0288, max_reward_err_index: 0, max_kl_dist: 0.1091, max_kl_dist_index: 0, max_train_grp_loss: 0.6531, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6543, max_val_grp_loss_index: 0
2024-10-23 00:47:33,662 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 44, train_loss: 0.6458, val_loss: 0.6500, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0288, 0.0288, 0.0288, KL_dist: 0.1092, 0.1092, 0.1092, param: [0.6776338219642639, 2.5820794105529785, 3.737903118133545, 3.596196174621582], weights: [0.3428042232990265, 0.3226119577884674, 0.3345838487148285], train_wt_loss:  0.6451, val_wt_loss: 0.6497, train_grp_loss: [0.6434300541877747, 0.6530876755714417, 0.6336010098457336], val_grp_loss: [0.65431147813797, 0.6489043235778809, 0.6466307044029236], max_reward_err: 0.0288, max_reward_err_index: 0, max_kl_dist: 0.1092, max_kl_dist_index: 0, max_train_grp_loss: 0.6531, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6543, max_val_grp_loss_index: 0
2024-10-23 00:47:34,502 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 45, train_loss: 0.6458, val_loss: 0.6500, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0288, 0.0288, 0.0288, KL_dist: 0.1092, 0.1092, 0.1092, param: [0.6781996488571167, 2.58241605758667, 3.73846173286438, 3.5965688228607178], weights: [0.3430149257183075, 0.32237592339515686, 0.33460918068885803], train_wt_loss:  0.6451, val_wt_loss: 0.6497, train_grp_loss: [0.6434201598167419, 0.6530798673629761, 0.6335919499397278], val_grp_loss: [0.654303789138794, 0.6488961577415466, 0.6466219425201416], max_reward_err: 0.0288, max_reward_err_index: 0, max_kl_dist: 0.1092, max_kl_dist_index: 0, max_train_grp_loss: 0.6531, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6543, max_val_grp_loss_index: 0
2024-10-23 00:47:35,373 - /Users/noesis/Code/group-robust-preference-optimization/algos/linear_bandit/common_gradient_descent.py[line:384] - INFO: Iteration: 46, train_loss: 0.6458, val_loss: 0.6500, grad_norm:  0.0094, live_grad: 0.0000, reward_err: 0.0288, 0.0288, 0.0288, KL_dist: 0.1092, 0.1092, 0.1092, param: [0.6787654757499695, 2.5827527046203613, 3.739020347595215, 3.5969414710998535], weights: [0.3432256281375885, 0.3221399784088135, 0.33463436365127563], train_wt_loss:  0.6450, val_wt_loss: 0.6497, train_grp_loss: [0.6434103846549988, 0.6530722975730896, 0.6335828900337219], val_grp_loss: [0.6542961597442627, 0.6488880515098572, 0.6466128826141357], max_reward_err: 0.0288, max_reward_err_index: 0, max_kl_dist: 0.1092, max_kl_dist_index: 0, max_train_grp_loss: 0.6531, max_train_grp_loss_index: 1, max_val_grp_loss: 0.6543, max_val_grp_loss_index: 0
